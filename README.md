# Convex-Optimisation-project
Multi-Class SVM

The basic idea of binary SVM is to find the hyperplane that maximises the margin between the different classes. By maximising the margin, SVM tries to create a decision boundary that is robust to noise and can generalise well to new data points.

However, in practical or real-world applications, the data could be more than 2 classes and hence in this draft we tried to focus on analysing the existing methods and their drawbacks with the help of concepts learnt during convex optimization courses. In this draft, we have analysed how a simple binary classifier SVM could be extended for multi-class classification. We have done an experimental analysis of the existing methods, which include one vs one and one vs all and multi-classification using hinge loss, and the results are shown on standard datasets i.e, IRIS and MNIST datasets
